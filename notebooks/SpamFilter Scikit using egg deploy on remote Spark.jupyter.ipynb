{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Uploading the packaged egg file to remote hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "upload success\n"
     ]
    }
   ],
   "source": [
    "# Push the egg file to user HDFS directory in the cluster\n",
    "import os\n",
    "import dsx_core_utils\n",
    "dsx_core_utils.upload_hdfs_file(\n",
    "    source_path=os.environ['DSX_PROJECT_DIR']+'/SpamFilterScikit/dist/SpamFilterScikit-1.0-py2.7.egg', \n",
    "    target_path=\"/user/user1/SpamFilterScikit-1.0-py2.7.egg\",\n",
    "    webhdfsurl=\"https://zinc1.fyre.ibm.com:8443/gateway/jalv-126-master-1/webhdfs/v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Uploading the datatset to remote cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "upload success\n"
     ]
    }
   ],
   "source": [
    "# Push the dataset to user HDFS directory in the cluster\n",
    "import dsx_core_utils\n",
    "dsx_core_utils.upload_hdfs_file(\n",
    "    source_path=os.environ['DSX_PROJECT_DIR']+'/datasets/SMSSpamCollection.csv', \n",
    "    target_path=\"/user/user1/SMSSpamCollection.csv\",\n",
    "    webhdfsurl=\"https://zinc1.fyre.ibm.com:8443/gateway/jalv-126-master-1/webhdfs/v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Connecting to remote spark through DSX-HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success configuring sparkmagic livy.\n",
      "['https://miniedge-hd.fyre.ibm.com:8443/gateway/jalv-126-master-1/livy2/v1', 'https://zinc1.fyre.ibm.com:8443/gateway/jalv-126-master-1/livy/v1', 'https://zinc1.fyre.ibm.com:8443/gateway/jalv-126-master-1/livy2/v1']\n"
     ]
    }
   ],
   "source": [
    "%load_ext sparkmagic.magics\n",
    "from dsx_core_utils import proxy_util,dsxhi_util\n",
    "proxy_util.configure_proxy_livy()\n",
    "\n",
    "dsxhi_util.list_livy_endpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pushing the python virtual environment to cluster using DSX-HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"imageId\": \"26611bf7fe595f786139d6d2132de070fc813f6a0ef7a4e25857b79c8cd4b565\",\r\n",
      "  \"scriptCommand\": \"anaconda2/bin/python2.7\",\r\n",
      "  \"libPaths\": [\"usr/local/spark-2.0.2-bin-hadoop2.7/python\",\"user-home/.scripts/common-helpers/batch/pmml\",\"user-home/.scripts/common-helpers/saas\"] }\r\n"
     ]
    }
   ],
   "source": [
    "!cat /user-home/_global_/.remote-images/dsx-hi/dsx-scripted-ml-python2.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Session Properties\n",
    "Using values from `dsx-scripted-ml-python2.json`, we'll need to:\n",
    "\n",
    "- (1) Pull the archive from HDFS to the Yarn Distributed cache using spark conf **--archives**\n",
    "- (2) Override the default PYSPARK_PYTHON, from the relative path `scriptCommand`\n",
    "\n",
    "---\n",
    "\n",
    "Example Livy Properties for using dsx-scripted-ml-python2.tar.gz Virtual Environment:\n",
    "```\n",
    "{\"proxyUser\": \"user1\", \"archives\": [\"/user/dsxhi/environments/26611bf7fe595f786139d6d2132de070fc813f6a0ef7a4e25857b79c8cd4b565/dsx-scripted-ml-python2.tar.gz\"],\"conf\":{\"spark.yarn.appMasterEnv.PYSPARK_PYTHON\":\"dsx-scripted-ml-python2.tar.gz/anaconda2/bin/python\"}}\n",
    "```\n",
    "### Files currently on HDFS:\n",
    "```\n",
    "/user/dsxhi/environments/26611bf7fe595f786139d6d2132de070fc813f6a0ef7a4e25857b79c8cd4b565/dsx-scripted-ml-python2.tar.gz\n",
    "/user/dsxhi/environments/pythonAddons/pythonAddons.tar.gz\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa75ea0a8a447e989b26d9092795d1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added endpoint https://zinc1.fyre.ibm.com:8443/gateway/jalv-126-master-1/livy2/v1\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>48</td><td>application_1525285700946_0040</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ales1.fyre.ibm.com:8088/proxy/application_1525285700946_0040/\">Link</a></td><td><a target=\"_blank\" href=\"http://ales6.fyre.ibm.com:8042/node/containerlogs/container_e27_1525285700946_0040_01_000001/user1\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Distributing the egg file to remote spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%spark\n",
    "sc.addPyFile(\"hdfs:///user/user1/SpamFilterScikit-1.0-py2.7.egg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Invoke the LRModelScikit custom method on remote cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.00%\n",
      "y_test  y_pred  count\n",
      "     1       1     94\n",
      "     0       1      4\n",
      "     1       0     10\n",
      "     0       0     92\n",
      "/hadoop/yarn/local/usercache/user1/appcache/application_1525285700946_0040/container_e27_1525285700946_0040_01_000001/dsx-scripted-ml-python2.tar.gz/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "import SpamFilterScikit\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import libraries from the deployed egg\n",
    "from SpamFilterScikit import LRModelScikit\n",
    "\n",
    "# Read the file from HDFS\n",
    "filename = \"hdfs:///user/user1/SMSSpamCollection.csv\"\n",
    "\n",
    "# Call the method\n",
    "LRModelScikit().execute(spark,filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 with DSX Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
